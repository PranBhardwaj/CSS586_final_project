Beverage Counting as an application for Computer Vision Models
Authors: Garrett Woelfl and Pranshu Bhardwaj

Tracking beverage service in busy bar environments is a complex and largely manual process, often leading to revenue loss. This project aims to automate drink counting using computer vision by leveraging security cameras already in use, enabling accurate tracking of drinks served from a certain area. Using YOLOv11 for object detection and tracking, the system identifies different types of drinkware and monitors their movement in real-time. The ultimate goal is to create a reliable, scalable solution that helps venues reduce shrinkage, streamline operations, and make data-driven decisions based on actual drink throughput.

According to the National Restaurant Association, industry estimates suggest that, on average, 20% of a restaurant's bar revenue is lost due to shrinkage each month. Shrinkage is the loss of inventory due to theft, fraud or error. The average bar revenue in the United States is $27,500 per month, and with expenses averaging $24,200, that leaves just $3,300 in profit, yet shrinkage  alone (assuming 20%) can cost $5,500 per month, wiping out profitability entirely.

Current bar management software allows for tracking inventory through weighing bottles and tracking tap usage, which is then compared to Point Of Sale (POS) systems. While these systems can get the job done, this requires time consuming employee effort, that is better spent improving the business in other ways. 
The bar owners shared an example of how theft occurs in their establishment. They suspected one of their employees was doing something wrong when they saw that they had an extremely large amount of tips compared to their sales, for multiple days in a row. 
To investigate their suspicion, the owner pulled up the security footage of the bar from those days and saw the following:
A couple walks into the bar and greets the server warmly, exchanging hugs, indicating they are familiar with each other. They place an order for drinks, and the server relays the order to the bartender. According to restaurant best practices, the bartender should only prepare drinks that have been entered into the POS system. However, during high-traffic periods, this rule is sometimes overlooked. The bartender prepared the drinks without POS confirmation, and the server delivered them to the couple.
This process repeated 7 times over the course of the evening.
When the couple finally requests the bill, the server approaches the POS kiosk, pauses for a moment, possibly making a decision,then prints and delivers the check. The couple reviews the bill, reacts with visible excitement, and orders 4 more rounds of drinks. A second bill is later provided, and they leave a large cash tip before exiting.
Upon reviewing the POS records, the bar owners discover that the couple was only charged for four drinks, despite the security footage showing they consumed 18 drinks.
Later that night, a similar incident occurred with another larger group, and they got 28 free drinks, compared to the 36 they ordered. In total the server cost the bar upwards of 700 dollars for two instances of theft in one service period. Considering this server had large tips the nights previous to this as well, they likely cost the bar nearly the entirety of their profits for the month within one week. This server had worked with them for over a year. This occurred with one server when their establishment has 30 servers, so there are likely others who do the same. 
The owners confidently agree with the industry estimates, saying that their staff consistently partake in these activities and simply cannot spend every day counting every drink served. The owners allow a few free drinks a day to various returning customers that bring in their friends and advertise their business outside of the establishment.
The bar owners want a system that eliminates the need to manually review hours of security footage. Instead, they prefer an automated solution that monitors transactions and alerts them to significant discrepancies between the number of drinks served and those recorded in the POS system. Ideally, the software should generate hourly reports detailing the number of drinks served, discrepancies detected, and associated staff members, allowing for quick and efficient oversight.
Our bar oversight system leverages existing security cameras to monitor drink distribution using computer vision. Beyond this, the final product will cross-check pouring events with POS transactions to detect missing sales. This will allow it to also flag and provide video evidence of potential theft, or unrecorded drinks. Later iterations could also detect signs of patron overservice (posture monitoring, or more simply drinks per hour) to improve liability protection.
By using deep learning, the system requires no bar-specific training, making it a plug-and-play solution that works out of the box in any bar setting.
With $5,500 in potential monthly losses, bar owners can't afford to not monitor their inventory more effectively. Our simple AI-driven solution provides instant ROI, recovering lost revenue while eliminating shrinkage-related profit losses, all without the need for expensive, manual tracking.

The current goal of our project is creation of the computer vision pipeline. This will mainly consist of python scripts that will preprocess the video footage, and the computer vision model that counts the beverages. This will be done with a pretrained RCNN model to simplify the process. 

A separate restaurant location has a more up to date camera system (the main location can only be accessed on site), allowing us to download previous days of footage and manipulate them however we see fit without risking harm to the integrity of the original footage.

After proof of concept, the owners agreed that they would be willing to extend the access to their other locations in order to see how the model handles other environments, glass types, and lighting situations.
Defining the Problem
In order to define what it means for a drink to be served, we originally wanted to count all drinks that are recognized on the left side of the green line in the image below. A drink is counted if it is classified and the centroid (the pink dot within the bounding box) is on the correct side of the line. This version proved that the model is capable of counting drinks as intended, but also led to a considerable amount of false positives, such as the shaker and the tub used to store cocktail mix. This version also showcases the capability to keep a consistent count of drinks as there are 4 recognized, and the output notes 3 drinks counted. 

Figure 1. The first version of the drink tracking model with misclassifications and the line showing region of interest behind the bar.

Out of curiosity, and to see how to reduce the problem size, we met with the owners and asked about how the POS system separates orders. Thankfully, the way they set up the POS system, the servers enter where the drinks are going, so the system can filter out drinks served at the bar top versus drinks served at the tables. This comes in handy when we take the next step in our approach.

To further  refine the process, and reduce all misclassifications, the region of interest can be recognized as the bar mat that the drinks are set on after they are prepared, and taken from once they are served. This is given to the model as the quadrilateral shown in the following image. As before, the drink is only counted if the centroid is within the set shape and is not counted otherwise. This new approach reduces misclassification to nearly zero, as there are little to no instances where something else aside from a drink to be served is set within this region.

Figure 2.  The redefined region of interest shown in pink, simplifies the problem further while still allowing for the majority of drinks to be correctly accounted for.

Referring to the user story, the servers at fault do not create cocktails themselves or pour beer for customers. General restaurant policy requires this as well. So this new region of interest will at least serve as a second confirmation that all drinks servers distribute in a day are accounted for in the POS system.

Comparison of YOLOv8 and YOLO11

The initial implementation of the drink detection pipeline utilized the YOLOv8m model, which proved effective in most scenarios, successfully identifying a variety of glasses and bottles within the designated region of interest. However, the model exhibited limitations in detecting certain glass types, such as stemmed cocktail glasses and specialty tumblers commonly used in bar environments. To address this, YOLO11 was evaluated as a potential improvement, with the aim of enhancing classification accuracy and overall system performance.

Switching to the YOLO11l model resulted in noticeable improvements in processing speed and inference efficiency, particularly during the analysis of extended video footage. Despite these gains in speed, the classification performance remained largely consistent with YOLOv8m. This is likely due to both versions being trained on similar datasets that lack sufficient variety in glassware, limiting the models' ability to generalize to less common drink types. It is expected that using a more capable YOLOv8 model, such as YOLOv8l, would yield similar results to YOLO11l in terms of classification accuracy. However, YOLO11 was chosen for continued use to ensure the system remains aligned with the most current model architecture and updates.

Other variants of YOLO11, such as YOLO11m, were also tested but did not demonstrate significant improvements over YOLOv8m. These lighter models offered no meaningful gains in accuracy or speed and, in practice, performed similarly to earlier versions. While newer YOLO models like YOLO11l can deliver performance and efficiency benefits, substantial improvements in detection accuracy will likely require domain-specific retraining on datasets that include a broader and more diverse range of bar glassware.


Table 1. A table with comparisons between YOLO11 models.

Hyperparameter Tuning

To improve the consistency and accuracy of drink tracking in the system, specific parameters within the botsort.yaml tracker configuration file are fine-tuned. A key parameter is track_buffer, which defines how many frames an object can temporarily disappear before the tracker considers it lost. By increasing this value, the system is better able to maintain consistent IDs for static objects—such as drinks left on a table—preventing premature ID drops and reducing the chances of duplicate counting when the object is redetected.

Another important parameter is match_thresh, which controls the confidence required to associate a detection with an existing track. Lowering this threshold slightly can help the tracker maintain associations under partial occlusion or brief visual inconsistencies, again improving object permanence.

In addition to the tracker settings, detection-level parameters in the code are also tuned. confidence_threshold is set to filter out weak detections, reducing noise, while iou_threshold is adjusted to manage how overlapping detections are resolved. The combination of these detection and tracking parameter adjustments ensures better stability in object tracking, especially for scenarios involving static or slow-moving items, and supports more accurate counting over time.



Possible Improvements

We may be able to enhance the model’s accuracy by incorporating posture recognition to identify when a bartender is carrying a drink, even if the drink is only partially visible. Implementing hand orientation tracking could support this capability by helping determine whether a bartender’s hand is obscuring the view of a drink. By extending the model to use YOLO’s person tracking features and integrating hand and arm position recognition, we can infer when a bartender is likely holding a drink and count it accordingly, even in cases of partial occlusion.

There is a clear need to create a custom dataset with more pictures of all drink glass types in order to get better performance of the model in this scenario. Potential issue with this is that if the custom dataset is too specific to the bar then this model will be less useful for other bar settings. Recognizing a flight paddle as one unit will also be challenging as the glasses used in a flight are similar enough to a regular serving glass that the model may count a flight as four separate glasses.

Next Steps

With the intent to provide this software as a service to the bar in these examples and the other locations associated with it, we have a few sub projects that need to be completed in order for it to be viable as a business product. The model needs to consistently deliver drink counts, recognize all drink types which are not supported currently such as shot glasses or flights, the model also needs to be migrated to a cloud service provider and connected directly to the camera system.

Considering this location sells 15000 drinks a month, and the user story suggests that the thief gave away 42 drinks in two days, we can safely assume that reporting 99.8% of the drinks sold is satisfactory for this application. Obviously 100% would be best, but due to constraints and issues such as bartenders obstructing camera view, we anticipate getting every drink counted with no miscounts will be rather difficult. However, it is very important to get this right as this capability is crucial for establishing trust with bar owners who need to be able to trust that the model reflects reality.

In order to improve the solutions' scalability to provide this software as a service to all of the bar locations and even other businesses, the system will have to be migrated to a cloud service such as AWS. This migration would allow for remote processing and centralization of analytics, reducing the hardware requirements of clients and depending on the compute requirements, speed up the software as we can spend more money on compute if needed. This step could also incorporate establishing a video stream pipeline that accepts the video directly from the camera in order to reduce wait time of recording the video  then uploading it to the cloud. This would also allow for near real time inference, allowing owners to catch bad actors in the act rather than waiting until the next day.

Overall, the progress of this project demonstrates that comprehensive drink tracking is a realistic and achievable goal. With the planned improvements such as support for additional glass types, posture-aware detection, and cloud deployment, we are confident that future iterations will deliver reliable and scalable performance. Once these features are implemented, the system can enter beta testing at additional restaurant locations to evaluate its effectiveness across diverse environments, including variations in lighting and bartender workflow. Successful validation across multiple sites will pave the way for long-term deployment, where the model can be used to process daily footage, flag discrepancies in daily reports, and provide actionable insights that help bar owners eliminate shrinkage and protect their profits.

